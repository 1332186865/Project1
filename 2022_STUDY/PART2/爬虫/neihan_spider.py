#  Copyright (c) 2022. Generated by Gu.
# coding=utf-8
import json
import re

import requests


class Neihan:
    def __init__(self):
        self.start_url = 'http://www.wlkankan.com/cate2/page2.html'
        self.next_url_temp = 'http://www.wlkankan.com/cate2/page{}.html'
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36'}

    def parse_url(self, url):
        response = requests.get(url, headers=self.headers)
        return response.content.decode()

    @staticmethod
    def get_first_page_content_list(html_str):
        content_list = re.findall(r'<section class="section.*?<div.*?<div.*?target="_blank">(.*?)</a><.*?</section>',
                                  html_str, re.S)
        max_time = re.findall("max_time:'(.*?)'", html_str)[0]
        print(content_list)
        return content_list, max_time

    @staticmethod
    def save_content_list(content_list):
        with open("neihan.txt", 'w', encoding="utf-8") as f:
            for content in content_list:
                f.write(json.dumps(content, ensure_ascii=False))
                f.write('\n')
        print('保存成功')

    @staticmethod
    def get_content_list(json_str):  # 提取从第二页开始的json中的数据
        dict_ret = json.loads(json_str)
        data = dict_ret["data"]["data"]
        content_list = [i["group"]["content"] for i in data]
        max_time = dict_ret["data"]["max_time"]
        has_more = dict_ret["data"]["has_more"]
        return content_list, max_time, has_more

    def run(self):
        # 1.start_url
        # 2,发送请求,获取响应
        html_str = self.parse_url(self.start_url)
        # 3,提取数据
        content_list, max_time = self.get_first_page_content_list(html_str)
        # 4.保存
        self.save_content_list(content_list)
        has_more = True
        while has_more:
            # 5.构造下一页的url地址
            next_url = self.next_url_temp.format(max_time)
            # 6.发送请求,获取响应
            json_str = self.parse_url(next_url)
            # 7,提取数据,提取max_time
            content_list, max_time, has_more = self.get_content_list(json_str)
            # 8.保存
            self.save_content_list(content_list)
            # 9.循环5-8步


if __name__ == '__main__':
    # !!伪代码无法运行(代码为apex异步网页， 网址为同步加载网页)
    neihan = Neihan()
    neihan.run()
