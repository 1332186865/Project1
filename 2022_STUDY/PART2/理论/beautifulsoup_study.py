#  Copyright (c) 2022. Generated by Gu.
from bs4 import BeautifulSoup

# 把需要解析的html内容从本地文件中读取出来
with open(r"./jupyter/爬虫基础/练习/zhihu.txt", 'r', encoding='utf-8') as reader:
    html = reader.read()
print(html)

# 首先通过 BeautifulSoup（） 实例化，我们传入的参数，第一个是需要解析的原始文本数据，也就是我们获得的网页；
# 第二个参数是解析器，使用 lxml，
soup = BeautifulSoup(html, 'lxml')
print(soup)

# 我们接下来可以使用 prettify 方法，对我们的 html 进行一个整理，让它的结构更清晰，方便我们看清不同节点的嵌套关系
print(soup.prettify())

print(soup.title)  # 找到第一个title节点  bs4.element.Tag数据结构
print(soup.title.name)  # 返回节点名称
print(soup.title.string)  # 返回节点的文本内容
print(soup.title.attrs)  # 返回节点属性 返回类型为字典

# 除了直接调用 soup.节点名称 以外，我们常常还会使用find方法来根据节点名称获取节点，或者通过节点的属性获取节点。
print(soup.find(name='h2'))
print(soup.find(attrs={'class': "HotItem-title"}))  # 均只返回找到的第一个内容

# 获取全部符合要求的节点及其内容： find_all() 查询所有符合条件的节点（标签）
# 1. 根据节点名(标签名)来查询元素
for a in soup.find_all(name='h2'):
    print(a.string)
# 2. 根据属性来查询; 属性的名称和值按照 字典的键值对的方式传入
for a in soup.find_all(attrs={'class': "HotItem-title"}):
    print(a.string)

# CSS选择器
# select() 方法：是一种使用 CSS 选择器的方法。网页是由一个个节点（标签）组成的，CSS 选择器就是定位这些节点，然后配置不同的样式，
# 通常是根据 id、class、标签名 进行筛选。若是CSS选择器的类型是id，那么选择方法是“#id”;若CSS选择器的类型是class，那么选择方法是“.class的值”；
# 如果CSS选择器的类型是一个节点（标签），选择方法是“标签名”。

import re

for item in soup.select(" .HotItem-metrics"):
    res = re.search('</svg>(.*?)热度', str(item), re.S)
    if res:
        print(res.group(1))

for item in soup.select(" .HotItem-content .HotItem-title"):
    print(item.string)
