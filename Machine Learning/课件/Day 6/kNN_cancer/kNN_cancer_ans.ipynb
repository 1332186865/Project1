{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍如何使用kNN进行乳腺癌诊断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.实验目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过本实验掌握kNN算法的原理，熟悉如何运用kNN算法解决真实世界问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实验知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kNN算法原理\n",
    "* kNN算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.预备知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 初等数学知识\n",
    "* Linux命令基本操作\n",
    "* Python编程基础\n",
    "* kNN算法原理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.kNN算法简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　k近邻法(k-nearest neighbor, kNN)是1967年由Cover T和Hart P提出的一种基本分类与回归方法。它的工作原理是：存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。  \n",
    "　　所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。  \n",
    "![](1_kNN_cancer.png)  \n",
    "　　上图中，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。  \n",
    "　　K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN方法虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。  \n",
    "　　KNN算法不仅可以用于分类，还可以用于回归。通过找出一个样本的k个最近邻居，将这些邻居的属性的平均值赋给该样本，就可以得到该样本的属性。更有用的方法是将不同距离的邻居对该样本产生的影响给予不同的权值(weight)，如权值与距离成反比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.kNN算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　a.计算已知类别数据集中的点与当前点之间的距离；  \n",
    "　　b.按照距离递增次序排序；  \n",
    "　　c.选取与当前点距离最小的k个点；  \n",
    "　　d.确定前k个点所在类别的出现频率；  \n",
    "　　e.返回前k个点所出现频率最高的类别作为当前点的预测分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验步骤：【基于kNN的乳腺癌诊断 】-背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乳腺癌是女性常见的恶性肿瘤之一,是威胁女性健康常见肿瘤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  实验步骤：【基于kNN的乳腺癌诊断】-准备数据数据解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据来源是UCI机器学习数据仓库的威廉康星乳腺癌诊断数据集。这个数据集包含569例细胞活检案例，每个案例有32个乳房肿块活检图像显示的细胞核的特征。第一个特征是ID，第二个是这个案例的癌症诊断结果，癌症诊断结果用编码\"M\"表示恶性，B表示良性。其他30个特征是数值型的其他指标，包括细胞核的半径(Radius)、质地(Texture)、周长(Perimeter)、面积(Area)和光滑度(Smoothness)等的均值、标准差和最大值。部分数据如下：  \n",
    "![](2_kNN_cancer.png)  \n",
    "可以看出各个特征的范围相差较大，直接使用原始数据计算距离将使分类器出现问题，所以应该使用标准化方法重新调整特征的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验步骤：【基于kNN的乳腺癌诊断】-准备数据数据归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先使用R读入数据并进行整理，代码及注释如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        B         M \n",
       "0.6274165 0.3725835 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   Benign Malignant \n",
       "0.6274165 0.3725835 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rm(list=ls())\n",
    "# 读入数据：\n",
    "wbcd<-read.table(\"wdbc.data.txt\",stringsAsFactors = F,header = T)\n",
    "# 删除ID：\n",
    "wbcd<-wbcd[,-1]\n",
    "# 查看肿瘤和良性的比例：\n",
    "prop.table(table(wbcd$Diagnosis))\n",
    "# 将Diagnosis转为因子并给标签\n",
    "wbcd$Diagnosis<-factor(wbcd$Diagnosis,levels=c(\"B\",\"M\"),labels = c(\"Benign\",\"Malignant\"))\n",
    "prop.table(table(wbcd$Diagnosis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出数据案例中恶性肿瘤占62.7%，良性占37.2%。  \n",
    "接着进行min-max标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于不同特征的范围差别很大，所以需要Min-Max归一化：\n",
    "normalize<-function(x){  return((x-min(x))/(max(x)-min(x)))}\n",
    "# 使用lapply对每一列进行标准化\n",
    "wbcd_n<-as.data.frame(lapply(wbcd[,2:31],normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据分为两部分：一部分是训练集（随机抽取469条）；一部分是是评估模型准确性的测试集（剩下的100条）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机取样100个作为测试集：\n",
    "test_100<-sample(1:nrow(wbcd_n),100)\n",
    "# 剩下的469个是训练集：\n",
    "train_w<-setdiff(1:nrow(wbcd_n),test_100)\n",
    "# 提取测试集数据：\n",
    "wbcd_test<-wbcd_n[test_100,]\n",
    "# 提取训练集数据：\n",
    "wbcd_train<-wbcd_n[train_w,]\n",
    "# 测试集诊断结果标签：\n",
    "wbcd_test_labels<-wbcd[test_100,1]\n",
    "# 训练集诊断结果标签：\n",
    "wbcd_train_labels<-wbcd[train_w,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用class包的knn()函数来实现本次训练和预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用class包的knn()函数：\n",
    "# 载入包\n",
    "library(class)\n",
    "# 进行训练预测：\n",
    "wbcd_test_pred<-knn(train = wbcd_train,test=wbcd_test,cl=wbcd_train_labels,k=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  实验步骤：【基于kNN的乳腺癌诊断】-测试算法验证分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建双向交叉表（gmodels包的CrossTable()函数）来评估模型的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  100 \n",
      "\n",
      " \n",
      "                 | wbcd_test_pred \n",
      "wbcd_test_labels |    Benign | Malignant | Row Total | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "          Benign |        57 |         0 |        57 | \n",
      "                 |     1.000 |     0.000 |     0.570 | \n",
      "                 |     0.877 |     0.000 |           | \n",
      "                 |     0.570 |     0.000 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "       Malignant |         8 |        35 |        43 | \n",
      "                 |     0.186 |     0.814 |     0.430 | \n",
      "                 |     0.123 |     1.000 |           | \n",
      "                 |     0.080 |     0.350 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "    Column Total |        65 |        35 |       100 | \n",
      "                 |     0.650 |     0.350 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "library(gmodels)\n",
    "CrossTable(x=wbcd_test_labels,y=wbcd_test_pred,prop.chisq = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图左上角的格子表示真阴性(True Negative)，这里表示分类器结果和临床结果一致认为是良性的情况，100个预测中有63个真阴性结果。相反，右下角就是真阳性(True Positive)结果，有32个案例分类器和临床一致认为是恶性的。左下的5个是假阴性(False Negative)，预测为良性实际是恶性，这可能导致病人错过治疗，这是最糟糕的预测结果。右上角的是假阳性(False Positive)，预测是恶性实际是良心，会导致病人虚惊一场。\n",
    "\n",
    "其他评估模型预测结果的方法如敏感性、特异性、ROC曲线及检验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  参考文献及延伸阅读 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考资料："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.哈林顿，李锐. 机器学习实战 : Machine learning in action[M]. 人民邮电出版社, 2013.  \n",
    "2.周志华. 机器学习:Machine learning[M]. 清华大学出版社, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 延伸阅读："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.李航. 统计学习方法[M]. 清华大学出版社, 2012."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
