{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验介绍协同过滤算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.实验目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过本实验掌握协同过滤算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实验知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 协同过滤算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* python 3.6.5  \n",
    "* CourseGrading在线实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.预备知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 初等数学知识  \n",
    "* Linux命令基本操作  \n",
    "* Python编程基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于协同过滤的推荐引擎 \n",
    "目前，我们接触到的比如网易云音乐的个性化推荐歌曲，淘宝的推荐物品，亚马逊的推荐图书等等。推荐引擎已经是一个很普遍的事物了。那么如何实现推荐功能呢？本节我们介绍一种协同过滤(collaborative filtering)的方法。协同过滤是通过将用户和其他用户的数据进行对比来实现推荐的。\n",
    "\n",
    "协同过滤算法通过对用户历史行为数据的挖掘发现用户的偏好，基于不同的偏好对用户进行群组划分并推荐品味相似的商品。协同过滤推荐算法分为两类，分别是基于用户的协同过滤算法(user-based collaboratIve filtering)，和基于物品的协同过滤算法(item-based collaborative filtering)。简单的说就是：人以类聚，物以群分。\n",
    "\n",
    "协同过滤与领域无关，它不需要知道现在对什么评分，谁在评分，评分是多少。而是基于各个类别之间的相似度来进行推荐。\n",
    "\n",
    "这里涉及到了相似度计算的问题。推荐引擎如何决定将哪个物品推荐给用户，就是取决于计算出的相似度排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似度计算 \n",
    "我们希望找到一种计算物品之间的相似度的定量的方法。利用用户对物品的评分来计算相似度，这就是协同过滤中使用的方法。\n",
    "\n",
    "下图中，给出了由一些用户及其对部分菜肴的评级信息所组成的矩阵。\n",
    "![](coll_filter/1_coll_filter.png)\n",
    "下面，我们基于所给数据矩阵，介绍三种相似度计算方法：\n",
    "### 1.欧式距离\n",
    "欧几里德距离评价是一个较为简单的用户关系评价方法。原理是通过计算两个用户在散点图中的距离来判断不同的用户是否有相同的偏好。我们计算一下手撕猪肉和烤牛肉之间的相似度。一开始我们使用欧氏距离来计算。手撕猪肉和烤牛肉的欧氏距离为：\n",
    "![](coll_filter/2_coll_filter.png)\n",
    "而手撕猪肉和鳗鱼饭的欧氏距离为：\n",
    "![](coll_filter/3_coll_filter.png)\n",
    "在该数据中，由于手撕猪肉和烤牛肉的距离小于手撕猪肉和鳗鱼饭的距离，因此手撕猪肉与烤牛肉比与鳗鱼饭更为相似。我们希望，相似度值在0到1之间变化，并且物品对越相似，它们的相似度值也就越大。我们可以用“相似度=1/(1+距离)”这样的算式来计算相似度。当距离为0时，相似度为1.0。如果距离真的非常大时，相似度也就趋近于0。\n",
    "### 2.皮尔逊相关系数(pearson correlation)\n",
    "它度量两个向量之间的相似度。该方法相对于欧氏距离的一个优势在于，它对用户评级的量级并不敏感。比如某个狂躁者对所有物品的评分都是5分，而另一个忧郁者对所有物品的评分都是1分，皮尔逊相关系数会认为这两个向量是相等的。在NumPy中，皮尔逊相关系数的计算是由函数corrcoef()进行的，后面我们很快就会用到它了。皮尔逊相关系数的取值范围从-1到+1，我们通过0.5 + 0.5*corrcoef()这个函数计算，并且把其取值范围归一化到0到1之间。\n",
    "### 3.余弦相似度(cosine similarity)\n",
    "计算的是两个向量夹角的余弦值。如果夹角为90度，则相似度为0；如果两个向量的方向相同，则相似度为1.0。同皮尔逊相关系数一样，余弦相似度的取值范围也在-1到+1之间，因此我们也将它归一化到0到1之间。计算余弦相似度值，我们采用的两个向量A和B夹角的余弦相似度的定义如下：\n",
    "![](coll_filter/4_coll_filter.png)\n",
    "接下来我们将上述各种相似度的计算方法写成Python中的函数。添加以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧氏距离：\n",
      "0.129731907557\n",
      "1.0\n",
      "皮尔逊相关系数：\n",
      "0.205965381738\n",
      "1.0\n",
      "余弦相似度：\n",
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as la\n",
    "\n",
    "def loadExData1():\n",
    "    return[[0, 0, 0, 2, 2],\n",
    "           [0, 0, 0, 3, 3],\n",
    "           [0, 0, 0, 1, 1],\n",
    "           [1, 1, 1, 0, 0],\n",
    "           [2, 2, 2, 0, 0],\n",
    "           [5, 5, 5, 0, 0],\n",
    "           [1, 1, 1, 0, 0]]\n",
    "\"\"\"\n",
    "函数说明：相似度计算函数(欧氏距离)\n",
    "parameters：\n",
    "    inA -列向量A\n",
    "    inB -列向量B\n",
    "return：\n",
    "    两个向量的相似度\n",
    "\"\"\"\n",
    "def ecludSim(inA, inB):\n",
    "    return 1.0/(1.0+la.norm(inA-inB))\n",
    "\"\"\"\n",
    "函数说明：相似度计算函数(皮尔逊相关系数)\n",
    "parameters：\n",
    "    inA -列向量A\n",
    "    inB -列向量B\n",
    "return：\n",
    "    两个向量的相似度\n",
    "\"\"\"\n",
    "def pearsSim(inA, inB):\n",
    "    if len(inA)<3: return 1.0   #是否存在三个或更多的点。两个向量是完全相关的，返回1\n",
    "    #print(corrcoef(inA,inB,rowvar=0))\n",
    "    return 0.5+0.5*corrcoef(inA,inB,rowvar=0)[0][1]     #将数据归一化到0到1之间\n",
    "\"\"\"\n",
    "函数说明：相似度计算函数(余弦相似度)\n",
    "parameters：\n",
    "    inA -列向量A\n",
    "    inB -列向量B\n",
    "return：\n",
    "    两个向量的相似度\n",
    "\"\"\"\n",
    "def cosSim(inA, inB):\n",
    "    num = float(inA.T*inB)  #计算分子\n",
    "    denom = la.norm(inA)*la.norm(inB)   #计算分母\n",
    "    return 0.5+0.5*(num/denom)  #归一化\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #测试相似度计算\n",
    "    myMat = mat(loadExData1())\n",
    "    print(\"欧氏距离：\")\n",
    "    print(ecludSim(myMat[:,0],myMat[:,4]))\n",
    "    print(ecludSim(myMat[:,0],myMat[:,0]))\n",
    "    print('皮尔逊相关系数：')\n",
    "    print(pearsSim(myMat[:,0],myMat[:,4]))\n",
    "    print(pearsSim(myMat[:,0],myMat[:,0]))\n",
    "    print('余弦相似度：')\n",
    "    print(cosSim(myMat[:,0],myMat[:,4]))\n",
    "    print(cosSim(myMat[:,0],myMat[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行后，我们可以看到对于物品0和物品4的相似度计算，以及物品0与自身的相似度计算，肯定是1啦！要注意的是，上述计算中都是假设数据采用了列向量方式来进行计算的。这里的列向量也暗示了我们将利用基于物品的相似度计算方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  基于物品的相似度还是用户的相似度 \n",
    "在上述计算中，我们是基于物品(item-based)的相似度。另一种计算方法为基于用户(user-based)的相似度，用来计算用户距离。在图中矩阵也可以看出，行为用户，列为物品。到底使用哪一种相似度呢？这取决于用户或物品的数目。基于物品相似度计算的时间会随物品数量的增加而增加，基于用户的相似度计算的时间则会随用户数量的增加而增加。如果我们有一个商店，那么最多会有几千件商品。如果用户的数目很多，那么我们可能倾向于使用基于物品相似度的计算方法。对于大部分产品导向的推荐引擎而言，用户的数量往大于物品的数量，即购买商品的用户数会多于出售的商品种类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推荐引擎的评价 \n",
    "如何对推荐引擎进行评价呢？此时，我们既没有预测的目标值，也没有用户来调查他们对预测的满意程度。这里我们就可以采用前面多次使用的交叉测试的方法。通常用于推荐引擎评价的指标是称为最小均方根误差（Root Mean Squared Error，RMSE）的指标，它首先计算均方误差的平均值然后取其平方根。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献与延伸阅读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考资料:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.哈林顿，李锐. 机器学习实战 : Machine learning in action[M]. 人民邮电出版社, 2013.  \n",
    "2.周志华. 机器学习:Machine learning[M]. 清华大学出版社, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 延伸阅读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.李航. 统计学习方法[M]. 清华大学出版社, 2012."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
