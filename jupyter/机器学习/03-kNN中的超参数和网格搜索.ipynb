{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc24040c",
   "metadata": {},
   "source": [
    "# 03-超参数和网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e580abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dee281f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c616bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f408bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = digits.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d0742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = digits.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bafb304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7306712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
       "       2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4, 1, 7,\n",
       "       7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 3, 3, 7, 3, 3, 4, 6,\n",
       "       6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4,\n",
       "       6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4289504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "        15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "        12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "         0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "        10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n",
       "         9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n",
       "        15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n",
       "         0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n",
       "        16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n",
       "        14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n",
       "         1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n",
       "         0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n",
       "        16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.],\n",
       "       [ 0.,  0.,  7., 15., 13.,  1.,  0.,  0.,  0.,  8., 13.,  6., 15.,\n",
       "         4.,  0.,  0.,  0.,  2.,  1., 13., 13.,  0.,  0.,  0.,  0.,  0.,\n",
       "         2., 15., 11.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 12., 12.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1., 10.,  8.,  0.,  0.,  0.,  8.,  4.,\n",
       "         5., 14.,  9.,  0.,  0.,  0.,  7., 13., 13.,  9.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  8.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1., 13.,  6.,  2.,  2.,  0.,  0.,  0.,\n",
       "         7., 15.,  0.,  9.,  8.,  0.,  0.,  5., 16., 10.,  0., 16.,  6.,\n",
       "         0.,  0.,  4., 15., 16., 13., 16.,  1.,  0.,  0.,  0.,  0.,  3.,\n",
       "        15., 10.,  0.,  0.,  0.,  0.,  0.,  2., 16.,  4.,  0.,  0.],\n",
       "       [ 0.,  0., 12., 10.,  0.,  0.,  0.,  0.,  0.,  0., 14., 16., 16.,\n",
       "        14.,  0.,  0.,  0.,  0., 13., 16., 15., 10.,  1.,  0.,  0.,  0.,\n",
       "        11., 16., 16.,  7.,  0.,  0.,  0.,  0.,  0.,  4.,  7., 16.,  7.,\n",
       "         0.,  0.,  0.,  0.,  0.,  4., 16.,  9.,  0.,  0.,  0.,  5.,  4.,\n",
       "        12., 16.,  4.,  0.,  0.,  0.,  9., 16., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 12., 13.,  0.,  0.,  0.,  0.,  0.,  5., 16.,  8.,\n",
       "         0.,  0.,  0.,  0.,  0., 13., 16.,  3.,  0.,  0.,  0.,  0.,  0.,\n",
       "        14., 13.,  0.,  0.,  0.,  0.,  0.,  0., 15., 12.,  7.,  2.,  0.,\n",
       "         0.,  0.,  0., 13., 16., 13., 16.,  3.,  0.,  0.,  0.,  7., 16.,\n",
       "        11., 15.,  8.,  0.,  0.,  0.,  1.,  9., 15., 11.,  3.,  0.],\n",
       "       [ 0.,  0.,  7.,  8., 13., 16., 15.,  1.,  0.,  0.,  7.,  7.,  4.,\n",
       "        11., 12.,  0.,  0.,  0.,  0.,  0.,  8., 13.,  1.,  0.,  0.,  4.,\n",
       "         8.,  8., 15., 15.,  6.,  0.,  0.,  2., 11., 15., 15.,  4.,  0.,\n",
       "         0.,  0.,  0.,  0., 16.,  5.,  0.,  0.,  0.,  0.,  0.,  9., 15.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0., 13.,  5.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9., 14.,  8.,  1.,  0.,  0.,  0.,  0., 12., 14., 14.,\n",
       "        12.,  0.,  0.,  0.,  0.,  9., 10.,  0., 15.,  4.,  0.,  0.,  0.,\n",
       "         3., 16., 12., 14.,  2.,  0.,  0.,  0.,  4., 16., 16.,  2.,  0.,\n",
       "         0.,  0.,  3., 16.,  8., 10., 13.,  2.,  0.,  0.,  1., 15.,  1.,\n",
       "         3., 16.,  8.,  0.,  0.,  0., 11., 16., 15., 11.,  1.,  0.],\n",
       "       [ 0.,  0., 11., 12.,  0.,  0.,  0.,  0.,  0.,  2., 16., 16., 16.,\n",
       "        13.,  0.,  0.,  0.,  3., 16., 12., 10., 14.,  0.,  0.,  0.,  1.,\n",
       "        16.,  1., 12., 15.,  0.,  0.,  0.,  0., 13., 16.,  9., 15.,  2.,\n",
       "         0.,  0.,  0.,  0.,  3.,  0.,  9., 11.,  0.,  0.,  0.,  0.,  0.,\n",
       "         9., 15.,  4.,  0.,  0.,  0.,  9., 12., 13.,  3.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc7e99",
   "metadata": {},
   "source": [
    "* 显示数据集中的某一个样本的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ffa592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = X[666]\n",
    "y[666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e725c94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b567e3d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit.reshape(8,8),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52f3602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, ptg):\n",
    "    n = int(ptg*X.shape[0])\n",
    "    if X.ndim == 1:\n",
    "        return X[:n],X[n:]\n",
    "    return np.vsplit(X,[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a92c436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb87b368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(X,0.8)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc18601e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(y, 0.8)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47352157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582753824756607"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 6\n",
    "ptg = 0.6\n",
    "my_knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "X_train, X_test = train_test_split(X,ptg)\n",
    "y_train, y_test = train_test_split(y,ptg)\n",
    "\n",
    "my_knn_classifier.fit(X_train,y_train)\n",
    "y_pred = my_knn_classifier.predict(X_test)\n",
    "accuracy = np.sum(y_pred==y_test) / y_test.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ee760",
   "metadata": {},
   "source": [
    "* 或者我们也可以直接调用sklearn封装好的方法——score来获取准确率，同时注意该方法只需要传入测试特征数据和目标向量即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3832d930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582753824756607"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_knn_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421012c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}\n",
    "for k in range(2,X_test.shape[0]//2):\n",
    "    my_knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    my_knn_classifier.fit(X_train,y_train)\n",
    "    accuracy = my_knn_classifier.score(X_test, y_test)\n",
    "    performance[k] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(performance.keys(), performance.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0e46a",
   "metadata": {},
   "source": [
    "```超参数```：  \n",
    "\n",
    "在运行机器学习算法前，有一些参数必须**提前指定**。比如在 KNN 算法中，k 就是超参数。  \n",
    "\n",
    "与超参数相对的参数叫做**模型参数**，即算法过程中的学习参数。kNN 算法没有模型参数。  \n",
    "\n",
    "**调参**指的是调整超参数，获得更好的模型效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c01bbc",
   "metadata": {},
   "source": [
    "**如何确定一个好的超参数？**  \n",
    "\n",
    "1. 具有待解决问题相关领域的知识；  \n",
    "2. 机器学习库封装的默认数值，即相对较好的经验数值；比如KNN的默认k值为5；  \n",
    "3. 实验搜索——尝试测试不同的k值，最终取效果最好的k值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92970c5c",
   "metadata": {},
   "source": [
    "### 寻找好的k值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e0db6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9680111265646731 3\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "best_k = -1\n",
    "for k in range(1,11):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    score = knn_clf.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "print(best_score, best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909195fa",
   "metadata": {},
   "source": [
    "在这种情况下，我们找到的最好的k值是3， 对应的准确率是0.968；  \n",
    "另外，如果我们找到的最好k值为10，有必要对10以上的k值再次进行搜索。因为一般来说，k值对应的准确率的变化是连续的，如果我们发现10作为一个1-10的边界k值，意味着10不一定是最好的，此时有必要检查大于10的k值对应的准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9927ca",
   "metadata": {},
   "source": [
    "* k值并非是KNN算法唯一的超参数。  \n",
    "\n",
    "<img src=\"resource/k.png\" style=\"zoom:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508b09c",
   "metadata": {},
   "source": [
    "* 普通的kNN算法中，当k=3，我们只看离黄色点最近的三个节点的颜色中，谁的数量多。比如现在按照之前讲的KNN算法，黄色节点的预测分类应该是绿色。但实际上黄色节点离红色节点更近，只是由于样本恰好是绿色多于红色的分布，会导致我们预测黄色节点的分类为绿色。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76dd44",
   "metadata": {},
   "source": [
    "* 如何对普通的kNN算法进行改进呢？我们可以将三个节点到黄色节点的距离的权重考虑进去。比如红色节点距离黄色节点近，那么在“投票”环节，它应该有更高的权重。  \n",
    "<img src=\"resource/改进knn.png\" style=\"zoom:40%\">  \n",
    "\n",
    "如果我们认为权重为距离的倒数：  \n",
    "红色：1；\n",
    "绿色：1/2 + 1/5 = 7/10  \n",
    "红色胜  \n",
    "\n",
    "这样做的另一个好处在于**“避免平票”**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996873e4",
   "metadata": {},
   "source": [
    "* 第二个超参数——weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494550c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9680111265646731 3 uniform\n"
     ]
    }
   ],
   "source": [
    "best_method = \"\"\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "for method in (\"uniform\",\"distance\"):\n",
    "    for k in range(1,11):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k,weights=method)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_method = method\n",
    "print(best_score, best_k, best_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972683e",
   "metadata": {},
   "source": [
    "* 第三个超参数——距离  \n",
    "\n",
    "1. 曼哈顿距离：  \n",
    "$$\\Sigma_{i=1}^{n}|X_{i}^{(a)}-X_{i}^{(b)}|$$   \n",
    "\n",
    "2. 欧拉距离：  \n",
    "$$(\\Sigma_{i=1}^{n}|X_{i}^{(a)}-X_{i}^{(b)}|^{2})^{1/2}$$\n",
    "\n",
    "<img src=\"resource/曼哈顿距离.jpg\" style=\"zoom:40%\">  \n",
    "3. 明可夫斯基距离（经过推广的曼哈顿、欧拉距离）\n",
    "$$(\\Sigma_{i=1}^{n}|X_{i}^{(a)}-X_{i}^{(b)}|^{p})^{1/p}$$\n",
    "\n",
    "p = 1，即曼哈顿距离；  \n",
    "p = 2, 欧拉距离；  \n",
    "\n",
    "第三个超参数——p  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70105629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707927677329624 3 4\n"
     ]
    }
   ],
   "source": [
    "best_p = -1\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "for k in range(1,11):\n",
    "    for p in range(1,6):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k,weights=\"distance\",\n",
    "                                      p=p)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_p = p\n",
    "print(best_score, best_k, best_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d987977",
   "metadata": {},
   "source": [
    "即使对于knn如此简单的算法，也有很多的超参数；寻找最好的超参数的方法可以使用搜索的方法。我们目前使用的搜索策略称之为——网格搜索。网格搜索的意识是采用我们目前多重循环的形式，判断每一种超参数的组合，寻找最好的超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36556d5f",
   "metadata": {},
   "source": [
    "### GridSearch  \n",
    "\n",
    "为了便于使用，sklearn封装好了网格搜索的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "984c7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义需要搜索的参数  \n",
    "\n",
    "param_grid = [{\n",
    "                 \"weights\":['uniform',\"distance\"],\n",
    "                 \"n_neighbors\":[i for i in range(2,11)],\n",
    "                 \"p\":[i for i in range(1,6)]\n",
    "              }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc52c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "439602f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b7b2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                          'p': [1, 2, 3, 4, 5],\n",
       "                          'weights': ['uniform', 'distance']}])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bcf7fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2, weights='distance')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_ # 最好的分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fea6028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 7, 8, 2, 0, 1, 2, 6, 3, 3, 7, 3, 3, 4, 6, 6, 6, 4, 9, 1, 5, 0,\n",
       "       9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7,\n",
       "       6, 8, 4, 3, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2,\n",
       "       5, 7, 3, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 8, 2, 3, 4, 5, 6, 7, 8, 9, 0,\n",
       "       9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4, 1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7,\n",
       "       8, 2, 0, 1, 2, 6, 3, 3, 7, 3, 3, 4, 6, 6, 6, 4, 9, 1, 5, 0, 9, 5,\n",
       "       2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 2, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8,\n",
       "       4, 3, 1, 4, 0, 5, 3, 6, 9, 6, 8, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7,\n",
       "       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0,\n",
       "       1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5,\n",
       "       5, 6, 5, 0, 9, 8, 9, 8, 4, 1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2,\n",
       "       0, 1, 2, 6, 3, 3, 7, 3, 3, 4, 6, 6, 6, 4, 9, 1, 5, 0, 9, 6, 2, 8,\n",
       "       3, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3,\n",
       "       1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5,\n",
       "       4, 1, 8, 4, 9, 0, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,\n",
       "       5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0,\n",
       "       9, 8, 9, 8, 4, 1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6,\n",
       "       3, 3, 7, 3, 3, 4, 6, 6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 1,\n",
       "       7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3, 1, 4, 0, 5,\n",
       "       3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 8, 4,\n",
       "       9, 0, 9, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 1, 9, 0, 1, 2, 3, 4, 5, 6,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6, 7, 1, 9, 4, 9, 5, 5, 6, 5, 0, 9, 8, 5, 8,\n",
       "       4, 1, 7, 7, 3, 5, 1, 0, 0, 0, 2, 7, 8, 2, 0, 1, 2, 6, 3, 3, 7, 7,\n",
       "       8, 4, 6, 6, 6, 9, 9, 1, 5, 0, 9, 5, 2, 8, 0, 1, 7, 6, 3, 2, 1, 7,\n",
       "       9, 6, 3, 1, 9, 9, 1, 7, 6, 8, 4, 3, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7,\n",
       "       5, 4, 4, 7, 2, 2, 5, 7, 3, 5, 9, 4, 5, 0, 8, 9, 8, 0, 1, 2, 3, 4,\n",
       "       5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 5, 4, 5, 6,\n",
       "       7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4, 1, 7, 7, 3, 5, 1, 0,\n",
       "       0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 3, 8, 7, 3, 3, 4, 6, 6, 6, 4, 9, 1,\n",
       "       5, 0, 9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9,\n",
       "       1, 7, 6, 8, 4, 5, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8,\n",
       "       2, 2, 5, 7, 9, 5, 4, 1, 1, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36ef3a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638386648122392"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39fe7db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2, 'p': 2, 'weights': 'distance'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_ # 最好分类器的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f72a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9592032730404825"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_ # 准确性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215af872",
   "metadata": {},
   "source": [
    "* 为什么准确性分数更低了？  \n",
    "\n",
    "因为GridSearch使用的准确性评分是有区别的，这就是GridSearchCV中CV的缘故。CV指 cross validation，为交叉验证法。  \n",
    "\n",
    "* 交叉验证法：  \n",
    "\n",
    "我们原先只是很简单的把数据集直接分成两部分，一部分训练模型，另一个部分测试模型。但由于这是随机的原始分组，所以最后模型的准确率的高低和数据原始分组有较大的关系。交叉验证法的全程是k-cross-validation,将数据集分为大小相等的k份，进行k次模型训练，每次都使用不同的一份作为测试数据集，剩下的9份是训练数据集，最终模型的准确性由k次准确性的均值来衡量。一般来说k是大于2的。在当前的GridSearchCV模块中，k值默认为5。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7804330",
   "metadata": {},
   "source": [
    "* GridSearchCV 可以传入更多的参数。。。  \n",
    "\n",
    "n_jobs: cpu使用几个核用于网格搜索；-1表示全部的核都用来进行搜索。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90a40906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                          'p': [1, 2, 3, 4, 5],\n",
       "                          'weights': ['uniform', 'distance']}])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(knn_clf, param_grid, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936c385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
