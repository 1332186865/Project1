#  Copyright (c) 2023. Generated by Gu.
#  -*- coding=utf-8 -*-
import logging
import os
import random
import re
from time import sleep

import requests


class Downloader:
    def __init__(self):
        # self.orig_folder = "../African_web_index/African_website/tsv"
        self.orig_folder = "../African_web_index/African_website/tsv"
        self.headers = {
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
                "Cache-Control": "max-age=0",
                "Cookie": "",
                "Dnt": "1",
                "Referer": "https://www.google.com/",
                "Sec-Ch-Ua": '"Chromium";v="118", "Google Chrome";v="118", "Not=A?Brand";v="99"',
                "Sec-Ch-Ua-Arch": '"x86"',
                "Sec-Ch-Ua-Bitness": '"64"',
                "Sec-Ch-Ua-Full-Version": '"118.0.5993.118"',
                "Sec-Ch-Ua-Full-Version-List": '"Chromium";v="118.0.5993.118", "Google Chrome";v="118.0.5993.118", '
                                               '"Not=A?Brand";v="99.0.0.0"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Model": '"',
                "Sec-Ch-Ua-Platform": '"Windows"',
                "Sec-Ch-Ua-Platform-Version": '"10.0"',
                "Sec-Ch-Ua-Wow64": "?0",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "same-origin",
                "Sec-Fetch-User": "?1",
                "Upgrade-Insecure-Requests": "1",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
                "X-Client-Data": "CLC1yQEIlbbJAQiltskBCKmdygEI3fnKAQiSocsBCJ3+zAEIhaDNAQiJss0BCNy9zQEIucrNAQjL1s0BCKjYzQEI0tvNAQj0280BCO3dzQEIk97NAQix3s0BCMjfzQEIteDNAQj5wNQVGPbJzQE="
                }

        self.logger = self.log()

    def get_cookie(self):
        """get new cookie"""
        with open("../../../../../2024_STUDY/PART1/Web_collection/cookie.txt", "r", encoding='utf-8') as file:
            data = file.read().strip()
            self.headers['Cookie'] = data

    def download(self):
        country_files = [f for f in os.listdir(self.orig_folder) if f.endswith('.tsv')]
        for country_file in country_files:
            with open(f"{self.orig_folder}/{country_file}", "r", encoding='utf-8') as file:
                country = country_file[:-4]
                for line in file:
                    media, country_url = line.strip().split("\t")
                    url = self.search_url_gene(country_url)
                    count = 0
                    while True:
                        try:
                            if count == 3:
                                raise SystemExit
                            self.parse_url(country, media, url)
                            count = 0
                            break
                        except Exception as e:
                            self.logger.error(f"Error: {e}")
                            self.logger.error(f"Error URL: {url}")
                            count += 1

            os.remove(f"{self.orig_folder}/{country_file}")
            self.logger.info(f"Deleted: {country_file}")
            sleep(random.randint(5, 10))

    @staticmethod
    def search_url_gene(country_url):
        search_content = (f'"zheng he" site:{country_url} -site:books.google.* -site:translate.google.com '
                          f'-site:www.google.* '
                          '-site:www.googleadservices.*')  # 搜索词
        return f"https://www.google.com/search?q={search_content}&safe=off&num=100"

    @staticmethod
    def remove_garbled_characters(text):
        text = re.sub(" ", "", text)
        text = re.sub("/", "", text)
        text = re.sub(":", "_", text)
        result = re.sub("-", "_", text)
        result = re.sub(" \| ", "_", text)
        return result

    @staticmethod
    def log():
        """log"""
        logger = logging.getLogger()
        logger.setLevel(logging.INFO)
        fh = logging.FileHandler("log.log", mode='a', encoding="UTF-8")
        sh = logging.StreamHandler()  # 创建日志处理器，在控制台打印
        formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s', '%Y-%m-%d %H:%M:%S')
        fh.setFormatter(formatter)
        sh.setFormatter(formatter)
        logger.addHandler(fh)
        logger.addHandler(sh)
        logger.info("log init")
        return logger

    def parse_url(self, country, title, url):
        """send request to get html and save it."""
        while True:
            self.logger.info(f"{country}, {title}")
            self.get_cookie()
            title = self.remove_garbled_characters(title)
            response = requests.get(url, headers=self.headers)
            file_path = f"./google_website/{country}-{title}.html"
            if response.status_code == 200:
                self.logger.info(f"{country}, {title} is downloaded.")
                with open(file_path, "wb") as f:
                    f.write(response.content)
                sleep(random.randint(10, 90))
                break
            else:
                self.logger.warning(f"Return Code: {response.status_code}")
                self.logger.warning(f"Need to deal with challenge!")
                self.logger.warning(url)
                self.logger.warning("Please refresh cookie")
                # self.logger.warning(response.text)
                sleep(random.randint(5, 15))
                input("Waiting...")

    def main(self):
        """main framework"""
        self.download()


if __name__ == '__main__':
    Downloader().main()
