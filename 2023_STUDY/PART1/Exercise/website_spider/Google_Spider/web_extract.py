#  Copyright (c) 2023. Generated by Gu.
#  -*- coding=utf-8 -*-
import os
import re

from bs4 import BeautifulSoup


class Finder:
    def __init__(self):
        self.data_folder = "./google_website"
        self.result_folder = "./web_address"
        self.web_data = []
        self.web_path = ''
        self.result_file = "result.tsv"
        self.wrong_article = []
        self.country_data = {}

    @staticmethod
    def remove_garbled_characters(text):
        text = re.sub(r"&amp;nbsp;×&amp;nbsp;", " x ", text)
        text = re.sub(r"&nbsp;", " ", text)
        # text = re.sub(r'<sup.*?</sup>', " ", text)
        text = re.sub(r'=E2=88=92 1', "-1", text)
        text = re.sub(r'=E2=80=99', "'", text)
        text = re.sub(r'=E2=80=93', "-", text)
        text = re.sub(r'=C3=A1', "a", text)
        text = re.sub(r'=..=..=..', "", text)
        text = re.sub(r'=..=..', "", text)
        text = re.sub(r'=\n', "", text)
        pattern = re.compile(r'[^\x00-\x7F]+')  # 定义正则表达式，用于匹配乱码字符
        result = re.sub(pattern, ' ', text, re.S)  # 使用空字符串替换乱码字符
        return result

    @staticmethod
    def temp_save(text):
        with open("./1.mhtml", "w", encoding="utf-8") as f:
            f.write(text)

    def save(self, item):
        with open(f'{self.result_folder}/{self.result_file}', 'a', encoding='utf-8') as f:
            f.write(item[0] + '\t' + item[1] + '\t' + item[2] + '\t' + item[3] + '\n')

    def method(self):
        if os.path.exists(f"{self.result_folder}/{self.result_file}"):
            os.remove(f"{self.result_folder}/{self.result_file}")
        html_files = [f for f in os.listdir(self.data_folder) if f.endswith('.html')]
        for html_file in html_files:
            temp = html_file[:-5].split("-")
            country, media = temp[0], temp[1]
            self.country_data[country] = self.country_data.get(country, 0) + 1
            with (open(f"{self.data_folder}/{html_file}", "r", encoding='utf-8') as f):
                print("Working: ", html_file)
                data = BeautifulSoup(f.read(), 'lxml')
                self.web_data = []
                self.web_path = f"{country}-{media}"

                topstuff = data.find('div', id='topstuff')
                search_body = data.find("div", id="search")
                if topstuff.text == '':
                    for item in search_body.div.div:
                        temp = item.div.div.div.div.div
                        if temp is not None:
                            title = temp.span.a.h3.text
                            address = temp.span.a['href']
                            self.save([country, media, title, address])
                print("Done: ", self.web_path)
        print(self.country_data)


if __name__ == '__main__':
    Finder().method()
